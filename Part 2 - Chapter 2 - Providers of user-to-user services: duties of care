#### CHAPTER 2

#### PROVIDERS OF USER-TO-USER SERVICES: DUTIES OF CARE

```
User-to-user services: duties of care
```
**5 Providers of user-to-user services: duties of care**

```
(1) Subsections (2) to (6) apply to determine which of the duties set out in this
Chapter and Chapter 3 apply in relation to a particular regulated user-to-user
service.
```
```
(2) All providers of regulated user-to-user services must comply with the
following duties in relation to each such service—
(a) the illegal content risk assessment duty (see section 7(1)),
(b) each of the illegal content duties (see section 9),
(c) the duty about rights to freedom of expression and privacy set out in
section 12(2),
(d) the duties about reporting and redress set out in—
(i) section 15(2)(a), and
(ii) section 15(3) and (5) so far as relating to subsection (4)(a)(i),
(b)(i) or (ii), (c)(i) or (d)(i) of that section, and
(e) each of the record-keeping and review duties (see section 16).
```
```
(3) Additional duties apply to providers of particular kinds of regulated user-to-
user services, as follows.
```
```
(4) All providers of regulated user-to-user services that are likely to be accessed by
children must comply with the following duties in relation to each such
service—
(a) each of the children’s risk assessment duties (see section 7(3) and (4)),
(b) each of the duties to protect children’s online safety (see section 10),
and
(c) the duties about reporting and redress set out in—
(i) section 15(2)(b), and
(ii) section 15(3) and (5) so far as relating to subsection (4)(a)(ii),
(c)(ii) or (d)(ii) of that section.
```
```
(5) All providers of Category 1 services must comply with the following duties in
relation to each such service—
(a) each of the adults’ risk assessment duties (see section 7(6) and (7)),
(b) each of the duties to protect adults’ online safety (see section 11),
(c) the duties about rights to freedom of expression and privacy set out in
section 12(3), (4) and (5),
(d) each of the duties to protect content of democratic importance (see
section 13),
(e) each of the duties to protect journalistic content (see section 14), and
(f) the duties about reporting and redress set out in—
(i) section 15(2)(c), and
(ii) section 15(3) and (5) so far as relating to subsection (4)(a)(iii),
(b)(iii) or (iv), (c)(iii) or (d)(iii) of that section.
```
```
(6) All providers of regulated user-to-user services that include a search engine
must comply with the following duties in relation to the search engine of each
such service—
(a) if the service is not likely to be accessed by children, the duties referred
to in section 17(2);
(b) if the service is likely to be accessed by children, the duties referred to
in section 17(2) and (3).
```
```
(7) For the meaning of “Category 1 service”, see section 59 (register of categories
of services).
```
**6 Duties of care: supplementary**

```
A duty set out in this Chapter which must be complied with in relation to a
user-to-user service extends only to—
(a) the design and operation of the service in the United Kingdom, or
(b) in the case of a duty that is expressed to apply in relation to users of a
service, the design and operation of the service as it affects United
Kingdom users of the service.

Risk assessments
```
**7 Risk assessment duties**

```
All services
```
```
(1) The “illegal content risk assessment duty” is a duty—
(a) to carry out an illegal content risk assessment at a time set out in section
8,
(b) to keep an illegal content risk assessment up to date, including when
OFCOM make any significant change to a risk profile that relates to
services of the kind in question, and
(c) to carry out a further illegal content risk assessment before making any
significant change to any aspect of the design or operation of a service
to which such an assessment is relevant.
```
```
Services likely to be accessed by children
```
```
(2) The “children’s risk assessment duties” are the duties set out in subsections (3)
and (4).
```
```
(3) A duty—
(a) to carry out a children’s risk assessment at a time set out in section 8,
(b) to keep a children’s risk assessment up to date, including when
OFCOM make any significant change to a risk profile that relates to
services of the kind in question, and
(c) to carry out a further children’s risk assessment before making any
significant change to any aspect of the design or operation of a service
to which such an assessment is relevant.

(4) Where a children’s risk assessment of a service identifies the presence of non-
designated content that is harmful to children, a duty to notify OFCOM of—
(a) the kinds of such content identified, and
(b) the incidence of those kinds of content on the service.
```
```
Category 1 services
```
```
(5) The “adults’ risk assessment duties” are the duties set out in subsections (6)
and (7).
```
```
(6) A duty—
(a) to carry out an adults’ risk assessment at a time set out in section 8,
(b) to keep an adults’ risk assessment up to date, including when OFCOM
make any significant change to a risk profile that relates to services of
the kind in question, and
(c) to carry out a further adults’ risk assessment before making any
significant change to any aspect of the design or operation of a service
to which such an assessment is relevant.
```
```
(7) Where an adults’ risk assessment of a service identifies the presence of content
that is harmful to adults, other than priority content that is harmful to adults,
a duty to notify OFCOM of—
(a) the kinds of such content identified, and
(b) the incidence of those kinds of content on the service.
```
```
Definitions
```
```
(8) An “illegal content risk assessment” of a service of a particular kind means an
assessment to identify, assess and understand such of the following as appear
to be appropriate, taking into account the risk profile that relates to services of
that kind—
(a) the user base;
(b) the level of risk of individuals who are users of the service encountering
the following by means of the service—
(i) terrorism content,
(ii) CSEA content,
(iii) priority illegal content, and
(iv) other illegal content,
taking into account (in particular) algorithms used by the service, and
how easily, quickly and widely content may be disseminated by means
of the service;
(c) the level of risk of harm to individuals presented by illegal content of
different descriptions;
(d) the level of risk of functionalities of the service facilitating the presence
or dissemination of illegal content, identifying and assessing those
functionalities that present higher levels of risk;
(e) the different ways in which the service is used, and the impact that has
on the level of risk of harm that might be suffered by individuals;
(f) the nature, and severity, of the harm that might be suffered by
individuals from the matters identified in accordance with paragraphs
(b) to (e);

(g) how the design and operation of the service (including the business
model, governance and other systems and processes) may reduce or
increase the risks identified.
```
```
(9) A “children’s risk assessment” of a service of a particular kind means an
assessment to identify, assess and understand such of the following as appear
to be appropriate, taking into account the risk profile that relates to services of
that kind—
(a) the user base, including the number of users who are children in
different age groups;
(b) the level of risk of children who are users of the service encountering
the following by means of the service—
(i) each kind of primary priority content that is harmful to children
(with each kind separately assessed),
(ii) each kind of priority content that is harmful to children (with
each kind separately assessed), and
(iii) non-designated content that is harmful to children,
giving separate consideration to children in different age groups, and
taking into account (in particular) algorithms used by the service and
how easily, quickly and widely content may be disseminated by means
of the service;
(c) the level of risk of harm to children presented by different descriptions
of content that is harmful to children, giving separate consideration to
children in different age groups;
(d) the level of risk of functionalities of the service facilitating the presence
or dissemination of content that is harmful to children, identifying and
assessing those functionalities that present higher levels of risk,
including functionalities—
(i) enabling adults to search for other users of the service
(including children), and
(ii) enabling adults to contact other users (including children) by
means of the service;
(e) the different ways in which the service is used, and the impact that has
on the level of risk of harm that might be suffered by children;
(f) the nature, and severity, of the harm that might be suffered by children
from the matters identified in accordance with paragraphs (b) to (e),
giving separate consideration to children in different age groups;
(g) how the design and operation of the service (including the business
model, governance and other systems and processes) may reduce or
increase the risks identified.
```
```
(10) An “adults’ risk assessment” of a service of a particular kind means an
assessment to identify, assess and understand such of the following as appear
to be appropriate, taking into account the risk profile that relates to services of
that kind—
(a) the user base;
(b) the level of risk of adults who are users of the service encountering the
following by means of the service—
(i) each kind of priority content that is harmful to adults (with each
kind separately assessed), and
(ii) other content that is harmful to adults,
taking into account (in particular) algorithms used by the service, and
how easily, quickly and widely content may be disseminated by means
of the service;
(c) the level of risk of harm to adults presented by different descriptions of
content that is harmful to adults;
(d) the level of risk of functionalities of the service facilitating the presence
or dissemination of content that is harmful to adults, identifying and
assessing those functionalities that present higher levels of risk;
(e) the different ways in which the service is used, and the impact that has
on the level of risk of harm that might be suffered by adults;
(f) the nature, and severity, of the harm that might be suffered by adults
from the matters identified in accordance with paragraphs (b) to (e);
(g) how the design and operation of the service (including the business
model, governance and other systems and processes) may reduce or
increase the risks identified.
```
```
(11) In this section references to risk profiles are to risk profiles included in
OFCOM’s guidance about risk assessments (see section 62).
```
**8 Timing of risk assessment under section 7**

```
(1) In the case of a regulated user-to-user service which is in operation
immediately before the relevant day, a risk assessment must be carried out
within the period of three months beginning with that day, unless extra time is
allowed by agreement with OFCOM.
```
```
(2) In the case of a regulated user-to-user service which begins operating on or
after the relevant day, a risk assessment must be carried out before United
Kingdom users are able to access the service.
```
```
(3) In the case of a user-to-user service which, having previously not been a
regulated user-to-user service, becomes a regulated user-to-user service, a risk
assessment must be carried out—
(a) before United Kingdom users are able to access the service, or
(b) if such users were already able to access the service, as soon as
reasonably practicable after the service becomes a regulated service.
```
```
(4) In this section “the relevant day” means—
(a) if OFCOM’s report of their risk assessment under section 61 and
OFCOM’s guidance about risk assessments under section 62 are first
published on the same day, that day, or
(b) if that report and that guidance are first published on different days, the
later of those days.
```
```
(5) In this section “risk assessment” means a risk assessment under section 7(1)(a),
(3)(a) or (6)(a).
```
```
Safety duties
```
**9 Safety duties about illegal content**

```
(1) The “illegal content duties” in relation to user-to-user services are the duties set
out in this section.

(2) A duty, in relation to a service, to take proportionate steps to mitigate and
effectively manage the risks of harm to individuals, as identified in the most
recent illegal content risk assessment of the service.
```
```
(3) A duty to operate a service using proportionate systems and processes
designed to—
(a) minimise the presence of priority illegal content;
(b) minimise the length of time for which priority illegal content is present;
(c) minimise the dissemination of priority illegal content;
(d) where the provider is alerted by a person to the presence of any illegal
content, or becomes aware of it in any other way, swiftly take down
such content.
```
```
(4) A duty to specify in the terms of service how individuals are to be protected
from illegal content, addressing each paragraph of subsection (3).
```
```
(5) A duty to ensure that—
(a) the terms of service referred to in subsection (4) are clear and accessible,
and
(b) those terms of service are applied consistently.
```
```
(6) In determining whether a step, system or process is proportionate for the
purposes of this section, the following must be taken into account—
(a) all the findings of the most recent illegal content risk assessment
(including as to levels of risk and as to nature, and severity, of potential
harm to individuals), and
(b) the size and capacity of the provider of a service.
```
```
(7) In this section “illegal content risk assessment” has the meaning given by
section 7(8).
```
```
(8) See also, in relation to duties under this section, section 12(2) (duties about
rights to freedom of expression and privacy).
```
**10 Safety duties for services likely to be accessed by children**

```
(1) The “duties to protect children’s online safety” in relation to user-to-user
services are the duties set out in this section.
```
```
(2) A duty, in relation to a service, to take proportionate steps to—
(a) mitigate and effectively manage the risks of harm to children in
different age groups, as identified in the most recent children’s risk
assessment of the service, and
(b) mitigate the impact of harm arising to children in different age groups
from content that is harmful to children present on the service.
```
```
(3) A duty to operate a service using proportionate systems and processes
designed to—
(a) prevent children of any age from encountering, by means of the service,
primary priority content that is harmful to children;
(b) protect children in age groups judged to be at risk of harm from other
content that is harmful to children (or from a particular kind of such
content) from encountering it by means of the service.
```
```
(4) A duty to specify in the terms of service—

(a) how children of any age are to be prevented from encountering
primary priority content that is harmful to children (with each kind of
primary priority content separately covered);
(b) how children in age groups judged to be at risk of harm from priority
content that is harmful to children (or from a particular kind of such
content) are to be protected from encountering it, where they are not
prevented from doing so (with each kind of priority content separately
covered);
(c) how children in age groups judged to be at risk of harm from non-
designated content that is harmful to children (or from a particular kind
of such content) are to be protected from encountering it, where they
are not prevented from doing so.
```
```
(5) A duty to ensure that—
(a) the terms of service referred to in subsection (4) are clear and accessible,
and
(b) those terms of service are applied consistently.
```
```
(6) In determining whether a step, system or process is proportionate for the
purposes of this section, the following must be taken into account—
(a) all the findings of the most recent children’s risk assessment (including
as to levels of risk and as to nature, and severity, of potential harm to
children), and
(b) the size and capacity of the provider of a service.
```
```
(7) So far as a duty in this section relates to non-designated content that is harmful
to children, the duty is to be taken to extend only to addressing risks of harm
from the kinds of such content that have been identified in the most recent
children’s risk assessment (if any have been identified).
```
```
(8) References in subsections (3)(b) and (4)(b) and (c) to children in age groups
judged to be at risk of harm from content that is harmful to children are
references to children in age groups judged to be at risk of such harm as
assessed by the provider of a service in the most recent children’s risk
assessment of the service.
```
```
(9) The duties in this section extend only to such parts of a service as it is possible
for children to access.
Section 26(3) applies for the purposes of this subsection as it applies for the
purposes of an assessment under section 26.
```
```
(10) In this section “children’s risk assessment” has the meaning given by section
7(9).
```
```
(11) See also, in relation to duties under this section, section 12(2) (duties about
rights to freedom of expression and privacy).
```
**11 Safety duties protecting adults: Category 1 services**

```
(1) The “duties to protect adults’ online safety” in relation to user-to-user services
are the duties set out in this section.
```
```
(2) A duty to specify in the terms of service—
(a) how priority content that is harmful to adults is to be dealt with by the
service (with each such kind of priority content separately covered),
and

(b) how other content that is harmful to adults, of a kind that has been
identified in the most recent adults’ risk assessment (if any kind of such
content has been identified), is to be dealt with by the service.
```
```
(3) A duty to ensure that—
(a) the terms of service referred to in subsection (2) are clear and accessible,
and
(b) those terms of service are applied consistently.
```
```
(4) In this section “adults’ risk assessment” has the meaning given by section 7(10).
```
```
(5) See also, in relation to duties under this section, section 12(2) (duties about
rights to freedom of expression and privacy).
```
```
Freedom of expression etc
```
**12 Duties about rights to freedom of expression and privacy**

```
(1) The duties about rights to freedom of expression and privacy in relation to
user-to-user services, as referred to in section 5, are the duties set out in this
section.
```
```
All services
```
```
(2) A duty to have regard to the importance of—
(a) protecting users’ right to freedom of expression within the law, and
(b) protecting users from unwarranted infringements of privacy,
when deciding on, and implementing, safety policies and procedures.
```
```
Category 1 services
```
```
(3) A duty—
(a) when deciding on safety policies and procedures, to carry out an
assessment of the impact that such policies or procedures would have
on—
(i) the protection of users’ right to freedom of expression within
the law, and
(ii) the protection of users from unwarranted infringements of
privacy; and
(b) to carry out an assessment of the impact of adopted safety policies and
procedures on the matters mentioned in paragraph (a)(i) and (ii).
```
```
(4) A duty to—
(a) keep an impact assessment up to date, and
(b) publish impact assessments.
```
```
(5) A duty to specify in the terms of service, or in a publicly available statement,
the positive steps that the provider has taken in response to an impact
assessment to—
(a) protect users’ right to freedom of expression within the law, and
(b) protect users from unwarranted infringements of privacy.
```
```
Definitions
```
```
(6) In this section—

“impact assessment” means an impact assessment under subsection (3);
“safety policies and procedures” means policies and procedures designed
to secure compliance with—
(a) any of the Chapter 2 safety duties, or
(b) any of the duties set out in section 15 (reporting and redress).
```
**13 Duties to protect content of democratic importance: Category 1 services**

```
(1) The “duties to protect content of democratic importance” in relation to user-to-
user services are the duties set out in this section.
```
```
(2) A duty to operate a service using systems and processes designed to ensure
that the importance of the free expression of content of democratic importance
is taken into account when making decisions about—
(a) how to treat such content (especially decisions about whether to take it
down or restrict users’ access to it), and
(b) whether to take action against a user generating, uploading or sharing
such content.
```
```
(3) A duty to ensure that the systems and processes mentioned in subsection (2)
apply in the same way to a diversity of political opinion.
```
```
(4) A duty to specify in the terms of service the policies and processes that are
designed to take account of the principle mentioned in subsection (2),
including, in particular, how that principle is applied to decisions mentioned
in that subsection.
```
```
(5) A duty to ensure that—
(a) the terms of service referred to in subsection (4) are clear and accessible,
and
(b) those terms of service are applied consistently.
```
```
(6) For the purposes of this section content is “content of democratic importance”,
in relation to a user-to-user service, if—
(a) the content is—
(i) news publisher content in relation to that service, or
(ii) regulated content in relation to that service; and
(b) the content is or appears to be specifically intended to contribute to
democratic political debate in the United Kingdom or a part or area of
the United Kingdom.
```
```
(7) In this section, the reference to “taking action” against a user is to giving a
warning to a user, or suspending or banning a user from using a service, or in
any way restricting a user’s ability to use a service.
```
```
(8) For the meaning of “news publisher content” and “regulated content”, see
section 39.
```
**14 Duties to protect journalistic content: Category 1 services**

```
(1) The “duties to protect journalistic content” in relation to user-to-user services
are the duties set out in this section.
```
```
(2) A duty to operate a service using systems and processes designed to ensure
that the importance of the free expression of journalistic content is taken into
account when making decisions about—

(a) how to treat such content (especially decisions about whether to take it
down or restrict users’ access to it), and
(b) whether to take action against a user generating, uploading or sharing
such content.
```
```
(3) A duty, in relation to a decision by a provider to take down content or to
restrict access to it, to make a dedicated and expedited complaints procedure
available to a person who considers the content to be journalistic content and
who is—
(a) the user who generated, uploaded or shared the content on the service,
or
(b) the creator of the content (see subsection (11)).
```
```
(4) A duty to make a dedicated and expedited complaints procedure available to
users of a service in relation to a decision by the provider of the service to take
action against a user because of content generated, uploaded or shared by the
user which the user considers to be journalistic content.
```
```
(5) A duty to ensure that—
(a) if a complaint about a decision mentioned in subsection (3) is upheld,
the content is swiftly reinstated on the service;
(b) if a complaint about a decision mentioned in subsection (4) is upheld,
the action against the user is swiftly reversed.
```
```
(6) A duty to specify in the terms of service—
(a) by what methods content present on the service is to be identified as
journalistic content;
(b) how the importance of the free expression of journalistic content is to
be taken into account when making decisions mentioned in subsection
(2);
(c) the policies and processes for handling complaints in relation to
content which is, or is considered to be, journalistic content.
```
```
(7) A duty to ensure that—
(a) the terms of service referred to in subsection (6) are clear and accessible,
and
(b) those terms of service are applied consistently.
```
```
(8) For the purposes of this section content is “journalistic content”, in relation to
a user-to-user service, if—
(a) the content is—
(i) news publisher content in relation to that service, or
(ii) regulated content in relation to that service;
(b) the content is generated for the purposes of journalism; and
(c) the content is UK-linked.
```
```
(9) For the purposes of this section content is “UK-linked” if—
(a) United Kingdom users of the service form one of the target markets for
the content (or the only target market), or
(b) the content is or is likely to be of interest to a significant number of
United Kingdom users.
```
```
(10) In this section references to “taking action” against a user are to giving a
warning to a user, or suspending or banning a user from using a service, or in
any way restricting a user’s ability to use a service.

(11) In this section the reference to a person who is the “creator” of content is a
reference to any of the following—
(a) in the case of news publisher content, the recognised news publisher in
question;
(b) an individual who—
(i) created the content, and
(ii) is in the United Kingdom;
(c) an entity which—
(i) created the content, and
(ii) is incorporated or formed under the law of any part of the
United Kingdom.
```
```
(12) For the meaning of “news publisher content”, “regulated content” and
“recognised news publisher”, see sections 39 and 40.
```
```
User reporting and redress
```
**15 Reporting and redress duties**

```
(1) The duties about reporting and redress in relation to user-to-user services, as
referred to in section 5, are the duties set out in this section.
```
```
(2) A duty to operate a service using systems and processes that allow users and
affected persons to easily report content of the following kinds—
(a) content which they consider to be illegal content;
(b) content, present on a part of a service that it is possible for children to
access, which they consider to be content that is harmful to children;
(c) content which they consider to be content that is harmful to adults.
```
```
(3) A duty to operate a complaints procedure in relation to a service that—
(a) allows for complaints of the kinds mentioned in subsection (4) to be
made,
(b) provides for appropriate action to be taken by the provider of the
service in response to such complaints, and
(c) is easy to access, easy to use (including by children) and transparent.
```
```
(4) The kinds of complaints are—
(a) complaints by users and affected persons about content of the
following kinds—
(i) content present on a service which they consider to be illegal
content;
(ii) content, present on a part of a service that it is possible for
children to access, which they consider to be content that is
harmful to children;
(iii) content present on a service which they consider to be content
that is harmful to adults;
(b) complaints by users and affected persons if they consider that—
(i) the provider is not complying with a Chapter 2 safety duty that
applies in relation to the service;
(ii) the provider is not complying with the duty set out in section
12(2);

(iii) the provider is not complying with any of the duties set out in
section 12(3) to (5);
(iv) the provider is not complying with any of the duties set out in
section 13 or 14;
(c) complaints by a user who has generated, uploaded or shared content
on a service if the provider—
(i) takes down that content because the provider considers that it
is illegal content;
(ii) takes down that content or restricts access to it because the
provider considers that it is content that is harmful to children;
(iii) takes down that content or restricts access to it because the
provider considers that it is content that is harmful to adults;
and
(d) complaints by a user if the provider has given a warning to the user,
suspended or banned the user from using the service, or in any other
way restricted the user’s ability to use the service, as a result of content
generated, uploaded or shared by the user which the provider
considers to be—
(i) illegal content;
(ii) content that is harmful to children;
(iii) content that is harmful to adults.
```
```
(5) A duty to make the policies and procedures that govern the handling and
resolution of complaints as mentioned in subsection (4) publicly available and
easily accessible (including to children).
```
```
(6) Section 26(3) (access by children to a service) applies for the purposes of
subsections (2)(b) and (4)(a)(ii) as it applies for the purposes of an assessment
under section 26.
```
```
(7) In this section “affected person” means a person, other than a user of the service
in question, who is in the United Kingdom and who is—
(a) the subject of the content,
(b) a member of a class or group of people with a certain characteristic (or
combination of characteristics) targeted by the content,
(c) a parent of, or other adult with responsibility for, a child who is a user
of the service or is the subject of the content, or
(d) an adult providing assistance in using the service to another adult who
requires such assistance, where that other adult is a user of the service
or is the subject of the content.
```
```
(8) See also, in relation to duties under this section, section 12(2) (duties about
rights to freedom of expression and privacy).
```
```
Record-keeping and review
```
**16 Record-keeping and review duties**

```
(1) The “record-keeping and review duties” in relation to user-to-user services are
the duties set out in this section.
```
```
(2) A duty to make and keep a written record of every risk assessment carried out
under section 7.

(3) A duty to make and keep a written record of any steps taken to comply with a
relevant duty other than steps which—
(a) are described in a code of practice and recommended for the purposes
of compliance with the duty in question, and
(b) apply in relation to the provider and the service in question.
```
```
(4) A duty to review compliance with the relevant duties in relation to a service—
(a) regularly, and
(b) as soon as reasonably practicable after making any significant change
to any aspect of the design or operation of the service.
```
```
(5) Where OFCOM consider it to be appropriate, OFCOM may, in relation to a
particular user-to-user service, exempt the provider of that service from—
(a) the duty set out in subsection (2),
(b) the duty set out in subsection (3), or
(c) the duties set out in subsections (2) and (3).
```
```
(6) OFCOM must publish details of any exemption under subsection (5).
```
```
(7) In this section—
“code of practice” means a code of practice published under section 34;
“relevant duties” means—
(a) the Chapter 2 safety duties,
(b) the duties set out in section 13 (content of democratic
importance),
(c) the duties set out in section 14 (journalistic content), and
(d) the duties set out in section 15 (reporting and redress).
```
